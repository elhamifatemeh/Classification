{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "news_classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Installation**"
      ],
      "metadata": {
        "id": "hJ1lefqPRwfM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvDPU_wnRg2v"
      },
      "outputs": [],
      "source": [
        "!pip install pandas\n",
        "!pip install -q hazm\n",
        "!pip install -q clean-text[gpl]\n",
        "!pip install sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import required packages**"
      ],
      "metadata": {
        "id": "iKqm8ruuR8AQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.layers import Dropout\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from hazm import *\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import numpy as np\n",
        "import math\n",
        "import re\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from plotly.offline import iplot, plot, download_plotlyjs, init_notebook_mode\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "from numpy import asarray\n",
        "#import seaborn as sb\n",
        "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
        "from copy import deepcopy\n",
        "from string import punctuation\n",
        "import random"
      ],
      "metadata": {
        "id": "8-wrYXapUmRe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification"
      ],
      "metadata": {
        "id": "MvFW9MgPCWUJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM model**"
      ],
      "metadata": {
        "id": "l1fFTNJyCcJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.25))\n",
        "model.add(LSTM(100, dropout=0.25, recurrent_dropout=0.25))\n",
        "model.add(Dense(82, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "epochs = 6\n",
        "batch_size = 64\n",
        "\n",
        "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
      ],
      "metadata": {
        "id": "SVwMK0cnCWt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prediction**"
      ],
      "metadata": {
        "id": "_yPf35_UCkkB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "O9E9ZvFECk9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "lRmiiu-5Cmq3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat = Corpus['Cat']\n",
        "\n",
        "unique_cat = np.unique(cat)\n",
        "\n",
        "#in the following lines of code we print how many posts are in each category\n",
        "cat_news_count = dict.fromkeys(unique_cat, 0)\n",
        "for cat in cat:\n",
        "  cat_news_count[cat] += 1\n",
        "\n",
        "for cat, cnt in cat_news_count.items():\n",
        "  print('Category \"{}\" contains {} posts.'.format(cat, cnt))"
      ],
      "metadata": {
        "id": "NAlKvhkQCm8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion matrix"
      ],
      "metadata": {
        "id": "DV8Ka_wDCrZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_Y_pred = np.argmax(Y_pred, axis=1)\n",
        "new_Y_test = np.argmax(Y_test, axis=1)\n",
        "\n",
        "## Plot confusion matrix\n",
        "cm = metrics.confusion_matrix(new_Y_test, new_Y_pred)\n",
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n",
        "            cbar=False)\n",
        "ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=unique_cat, \n",
        "       yticklabels=unique_cat, title=\"Confusion matrix\")\n",
        "plt.yticks(rotation=0)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pYEy6NSSCrqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy"
      ],
      "metadata": {
        "id": "grxEtxoyCztX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the accuracy of training data and validation data\n",
        "corrects = 0\n",
        "for i in range(len(new_Y_pred)):\n",
        "    if int(new_Y_pred[i]) is int(new_Y_test[i]):\n",
        "        corrects += 1\n",
        "        \n",
        "accuracy = float(corrects / len(new_Y_pred))*100\n",
        "print('Accuracy (using \"{}\" column): {} %'.format ('Text', accuracy))\n",
        "\n",
        "accr = model.evaluate(X_test,Y_test)\n",
        "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
      ],
      "metadata": {
        "id": "OOGeX3WwC0nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test model**"
      ],
      "metadata": {
        "id": "Gu_GoV9hC3yY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_X_test = []\n",
        "random_Y_test = []\n",
        "counter = 0\n",
        "\n",
        "for i in range(100):\n",
        "  rnd = random.randint(0, len(X_test)-1)\n",
        "  random_X_test.append(X_test[rnd])\n",
        "  random_Y_test.append(Y_test[rnd])\n",
        "\n",
        "#print(random_X_test)\n",
        "#print(random_Y_test)\n",
        "\n",
        "\n",
        "for x in range(len(random_X_test)):\n",
        "  Y_pred = model.predict(asarray([random_X_test[x]]))\n",
        "  #print(Y_pred)\n",
        "  pred_class = np.argmax(Y_pred)\n",
        "  print(pred_class)\n",
        "  \n",
        "  if(pred_class == np.where(random_Y_test[x] == 1)):\n",
        "    print('predicted correctly')\n",
        "    counter += 1\n",
        "  else: \n",
        "    print('predicted wrongly')\n",
        "\n",
        "#print(counter)\n",
        "print('Number of correct predictions: {}\"'.format(counter))"
      ],
      "metadata": {
        "id": "tSHDRQ5dC7An"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}